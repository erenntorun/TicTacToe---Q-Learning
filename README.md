ğŸ§  Tic-Tac-Toe AI with Q-Learning
Bu proje, klasik Tic-Tac-Toe (XOX) oyununu oynayan ve Ã¶ÄŸrenen bir yapay zekÃ¢ (AI) ajanÄ± iÃ§erir. Q-Ã–ÄŸrenme (Q-Learning) algoritmasÄ± kullanÄ±larak eÄŸitilen bu ajan, zamanla oyun stratejilerini geliÅŸtirerek insan oyunculara karÅŸÄ± daha baÅŸarÄ±lÄ± hale gelir.

ğŸ® Ã–zellikler
ğŸ•¹ï¸ Ä°nsan vs. Yapay ZekÃ¢ modu
ğŸ§  Q-learning tabanlÄ± kendini geliÅŸtiren yapay zekÃ¢
ğŸ’¾ Q-table kaydetme/yÃ¼kleme (pickle ile)
ğŸ” EÄŸitilebilir yapÄ±: X ya da O olarak eÄŸitim
ğŸ“Š EÄŸitim sonrasÄ± performans Ã§Ä±ktÄ±larÄ±

ğŸ“ Dosya YapÄ±sÄ±
â”œâ”€â”€ Agent.py         # Q-learning ajanÄ±
â”œâ”€â”€ TicTacToe.py     # Oyun mekaniÄŸi
â”œâ”€â”€ main.py          # Oyunu Ã§alÄ±ÅŸtÄ±rmak veya ajanÄ± eÄŸitmek iÃ§in kullanÄ±lan dosya
â”œâ”€â”€ brainX           # EÄŸitilmiÅŸ X oyuncusu (pickle dosyasÄ±, eÄŸitim sonrasÄ± oluÅŸur)
â”œâ”€â”€ brainO           # EÄŸitilmiÅŸ O oyuncusu (pickle dosyasÄ±, eÄŸitim sonrasÄ± oluÅŸur)

ğŸ§ª NasÄ±l Ã‡alÄ±ÅŸÄ±r?
1. AjanÄ± EÄŸitmek:

from TicTacToe import TicTacToe
from Agent import Agent

game = TicTacToe()
agent = Agent(game, 'X', discount_factor=0.6, episode=100000)
agent.train_brain_x_byrandom()

2. Ä°nsanla Oynamak
agent = Agent(game, 'X')
agent.play_with_human()

ğŸ› ï¸ Parametreler
Parametre	          AÃ§Ä±klama
episode	            EÄŸitim boyunca oynanacak oyun sayÄ±sÄ±
epsilon	            KeÅŸfetme oranÄ± (rastgele hareket olasÄ±lÄ±ÄŸÄ±)
discount_factor	    Q-learning geriye yayÄ±lÄ±m katsayÄ±sÄ±
eps_reduce_factor	  Her 1000 oyunda epsilonâ€™un azaltÄ±lma oranÄ±

ğŸ’¡ Tavsiyeler
*discount_factor:
  -X oyuncusu iÃ§in: 0.6
  -O oyuncusu iÃ§in: 0.5
*EÄŸitim sÃ¼resi olarak en az 100000 episode Ã¶nerilir.
*Ä°lk hamlede rastgelelik bÄ±rakÄ±larak daha Ã§eÅŸitli stratejiler Ã¶ÄŸrenilir.

ğŸ“· Ekran GÃ¶rÃ¼ntÃ¼sÃ¼
 X     --     O  
 --    X     O  
 --    --    X  
_______________
X is Winner!
